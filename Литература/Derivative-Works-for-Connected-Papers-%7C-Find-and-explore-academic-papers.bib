@article{0f23a44418aabe3344c6f3809d6a8ab898292813,
title = {Data Invariants to Understand Unsupervised Out-of-Distribution Detection},
year = {2021},
url = {https://www.semanticscholar.org/paper/0f23a44418aabe3344c6f3809d6a8ab898292813},
abstract = {S2 TL;DR: A characterization of U-OOD is proposed based on the invariants of the training dataset and it is shown how this characterization is unknowingly embodied in the top-scoring MahaAD method, thereby explaining its quality.},
author = {Lars Doorenbos and R. Sznitman and Pablo M'arquez-Neila},
journal = {ArXiv},
volume = {abs/2111.13362},
pages = {null},
doi = {10.1007/978-3-031-19821-2_8},
arxivid = {2111.13362},
}

@article{8b153cc2c7f5ea9f307f12ea945a5e9196ee5c52,
title = {A Unified Survey on Anomaly, Novelty, Open-Set, and Out-of-Distribution Detection: Solutions and Future Challenges},
year = {2021},
url = {https://www.semanticscholar.org/paper/8b153cc2c7f5ea9f307f12ea945a5e9196ee5c52},
abstract = {Machine learning models often encounter samples that are diverged from the training distribution. Failure to recognize an out-of-distribution (OOD) sample, and consequently assign that sample to an in-class label significantly compromises the reliability of a model. The problem has gained significant attention due to its importance for safety deploying models in open-world settings. Detecting OOD samples is challenging due to the intractability of modeling all possible unknown distributions. To date, several research domains tackle the problem of detecting unfamiliar samples, including anomaly detection, novelty detection, one-class learning, open set recognition, and out-of-distribution detection. Despite having similar and shared concepts, out-of-distribution, open-set, and anomaly detection have been investigated independently. Accordingly, these research avenues have not cross-pollinated, creating research barriers. While some surveys intend to provide an overview of these approaches, they seem to only focus on a specific domain without examining the relationship between different domains. This survey aims to provide a cross-domain and comprehensive review of numerous eminent works in respective areas while identifying their commonalities. Researchers can benefit from the overview of research advances in different fields and develop future methodology synergistically. Furthermore, to the best of our knowledge, while there are surveys in anomaly detection or one-class learning, there is no comprehensive or up-to-date survey on out-of-distribution detection, which our survey covers extensively. Finally, having a unified cross-domain perspective, we discuss and shed light on future lines of research, intending to bring these fields closer together.},
author = {Mohammadreza Salehi and Hossein Mirzaei and Dan Hendrycks and Yixuan Li and M. Rohban and M. Sabokrou},
journal = {Trans. Mach. Learn. Res.},
volume = {2022},
pages = {null},
arxivid = {2110.14051},
}

@article{2494d35c9c84f9b3cede710c16b7f78e9cee3738,
title = {Rethinking Assumptions in Deep Anomaly Detection},
year = {2020},
url = {https://www.semanticscholar.org/paper/2494d35c9c84f9b3cede710c16b7f78e9cee3738},
abstract = {Though anomaly detection (AD) can be viewed as a classification problem (nominal vs. anomalous) it is usually treated in an unsupervised manner since one typically does not have access to, or it is infeasible to utilize, a dataset that sufficiently characterizes what it means to be "anomalous." In this paper we present results demonstrating that this intuition surprisingly does not extend to deep AD on images. For a recent AD benchmark on ImageNet, classifiers trained to discern between normal samples and just a few (64) random natural images are able to outperform the current state of the art in deep AD. We find that this approach is also very effective at other common image AD benchmarks. Experimentally we discover that the multiscale structure of image data makes example anomalies exceptionally informative.},
author = {Lukas Ruff and Robert A. Vandermeulen and Billy Joe Franks and K. Muller and M. Kloft},
journal = {ArXiv},
volume = {abs/2006.00339},
pages = {null},
arxivid = {2006.00339},
}

@article{f98dbe64ed6fa8925048291fcceb625d704fb294,
title = {Self-Supervised Anomaly Detection: A Survey and Outlook},
year = {2022},
url = {https://www.semanticscholar.org/paper/f98dbe64ed6fa8925048291fcceb625d704fb294},
abstract = {Over the past few years, anomaly detection, a subfield of machine learning that is mainly concerned with the detection of rare events, witnessed an immense improvement following the unprecedented growth of deep learning models. Recently, the emergence of self-supervised learning has sparked the development of new anomaly detection algorithms that surpassed state-of-the-art accuracy by a significant margin. This paper aims to review the current approaches in self-supervised anomaly detection. We present technical details of the common approaches and discuss their strengths and drawbacks. We also compare the performance of these models against each other and other state-of-the-art anomaly detection models. Finally, we discuss a variety of new directions for improving the existing algorithms.},
author = {H. Hojjati and Thi Kieu Khanh Ho and N. Armanfard},
journal = {ArXiv},
volume = {abs/2205.05173},
pages = {null},
doi = {10.48550/arXiv.2205.05173},
arxivid = {2205.05173},
}

@article{13fab6dbb9d0f3eaac0b45a52c140165ae25b8b6,
title = {GAN-based anomaly detection: A review},
year = {2022},
url = {https://www.semanticscholar.org/paper/13fab6dbb9d0f3eaac0b45a52c140165ae25b8b6},
abstract = {null},
author = {X. Xia and Xizhou Pan and Nan Li and Xing He and Lin Ma and Xiaoguang Zhang and N. Ding},
journal = {Neurocomputing},
volume = {493},
pages = {497-535},
doi = {10.1016/j.neucom.2021.12.093},
}

@article{d4be8d5d91a78c1065f8579c1a64ea05eb455ba4,
title = {Improving Novelty Detection using the Reconstructions of Nearest Neighbours},
year = {2021},
url = {https://www.semanticscholar.org/paper/d4be8d5d91a78c1065f8579c1a64ea05eb455ba4},
abstract = {S2 TL;DR: This work shows that using nearest neighbours in the latent space of autoencoders (AE) signiﬁcantly improves performance of semi-supervised novelty detection in both single and multi-class contexts, and demonstrates that the nearest-latent-neighbours (NLN) algorithm is memory and time efﬂcient, does not require signi-cant data augmentation, nor is reliant on pretrained networks.},
author = {Michael Mesarcik and E. Ranguelova and A. Boonstra and R. V. Nieuwpoort},
journal = {Array},
volume = {14},
pages = {100182},
doi = {10.1016/j.array.2022.100182},
arxivid = {2111.06150},
}

@article{5b9f294a37799a454543c4ce3d9cb40bdb2ad9a4,
title = {Exposing Outlier Exposure: What Can Be Learned From Few, One, and Zero Outlier Images},
year = {2022},
url = {https://www.semanticscholar.org/paper/5b9f294a37799a454543c4ce3d9cb40bdb2ad9a4},
abstract = {Due to the intractability of characterizing everything that looks unlike the normal data, anomaly detection (AD) is traditionally treated as an unsupervised problem utilizing only normal samples. However, it has recently been found that unsupervised image AD can be drastically improved through the utilization of huge corpora of random images to represent anomalousness; a technique which is known as Outlier Exposure. In this paper we show that specialized AD learning methods seem unnecessary for state-of-the-art performance, and furthermore one can achieve strong performance with just a small collection of Outlier Exposure data, contradicting common assumptions in the field of AD. We find that standard classifiers and semi-supervised one-class methods trained to discern between normal samples and relatively few random natural images are able to outperform the current state of the art on an established AD benchmark with ImageNet. Further experiments reveal that even one well-chosen outlier sample is sufficient to achieve decent performance on this benchmark (79.3% AUC). We investigate this phenomenon and find that one-class methods are more robust to the choice of training outliers, indicating that there are scenarios where these are still more useful than standard classifiers. Additionally, we include experiments that delineate the scenarios where our results hold. Lastly, no training samples are necessary when one uses the representations learned by CLIP, a recent foundation model, which achieves state-of-the-art AD results on CIFAR-10 and ImageNet in a zero-shot setting.},
author = {Philipp Liznerski and Lukas Ruff and Robert A. Vandermeulen and Billy Joe Franks and K. Muller and Marius Kloft},
journal = {Trans. Mach. Learn. Res.},
volume = {2022},
pages = {null},
doi = {10.48550/arXiv.2205.11474},
arxivid = {2205.11474},
}

@article{cf122c84af8c85e15c3dffaca4069dd455b56a1e,
title = {Visual Anomaly Detection for Images: A Survey},
year = {2021},
url = {https://www.semanticscholar.org/paper/cf122c84af8c85e15c3dffaca4069dd455b56a1e},
abstract = {Visual anomaly detection is an important and challenging problem in the field of machine learning and computer vision. This problem has attracted a considerable amount of attention in relevant research communities. Especially in recent years, the development of deep learning has sparked an increasing interest in the visual anomaly detection problem and brought a great variety of novel methods. In this paper, we provide a comprehensive survey of the classical and deep learning-based approaches for visual anomaly detection in the literature. We group the relevant approaches in view of their underlying principles and discuss their assumptions, advantages, and disadvantages carefully. We aim to help the researchers to understand the common principles of visual anomaly detection approaches and identify promising research directions in this field.},
author = {Jie Yang and Rui Xu and Zhiquan Qi and Yong Shi},
journal = {ArXiv},
volume = {abs/2109.13157},
pages = {null},
arxivid = {2109.13157},
}

@article{fa1aa090d09dc5d420d0cce37cea72c21e99d36b,
title = {Deep One-Class Classification via Interpolated Gaussian Descriptor},
year = {2021},
url = {https://www.semanticscholar.org/paper/fa1aa090d09dc5d420d0cce37cea72c21e99d36b},
abstract = {One-class classification (OCC) aims to learn an effective data description to enclose all normal training samples and detect anomalies based on the deviation from the data description. Current state-of-the-art OCC models learn a compact normality description by hyper-sphere minimisation, but they often suffer from overfitting the training data, especially when the training set is small or contaminated with anomalous samples. To address this issue, we introduce the interpolated Gaussian descriptor (IGD) method, a novel OCC model that learns a one-class Gaussian anomaly classifier trained with adversarially interpolated training samples. The Gaussian anomaly classifier differentiates the training samples based on their distance to the Gaussian centre and the standard deviation of these distances, offering the model a discriminability w.r.t. the given samples during training. The adversarial interpolation is enforced to consistently learn a smooth Gaussian descriptor, even when the training data is small or contaminated with anomalous samples. This enables our model to learn the data description based on the representative normal samples rather than fringe or anomalous samples, resulting in significantly improved normality description. In extensive experiments on diverse popular benchmarks, including MNIST, Fashion MNIST, CIFAR10, MVTec AD and two medical datasets, IGD achieves better detection accuracy than current state-of-the-art models. IGD also shows better robustness in problems with small or contaminated training sets.},
author = {Yuanhong Chen and Yu Tian and Guansong Pang and G. Carneiro},
doi = {10.1609/aaai.v36i1.19915},
arxivid = {2101.10043},
}

@article{c85a9d25147b0eaf765855df475dc5cd95e4d2f5,
title = {Transfer-Based Semantic Anomaly Detection},
year = {2021},
url = {https://www.semanticscholar.org/paper/c85a9d25147b0eaf765855df475dc5cd95e4d2f5},
abstract = {Detecting semantic anomalies is challenging due to the countless ways in which they may appear in real-world data. While enhancing the robustness of networks may be sufﬁcient for modeling simplistic anomalies, there is no good known way of preparing models for all potential and unseen anomalies that can potentially occur, such as the appearance of new object classes. In this paper, we show that a previously overlooked strategy for anomaly detection (AD) is to introduce an explicit inductive bias toward representations transferred over from some large and varied semantic task. We rigorously verify our hypothesis in controlled trials that utilize intervention, and show that it gives rise to surprisingly effective auxiliary objec-tives that outperform previous AD paradigms.},
author = {Lucas Deecke and Lukas Ruff and Robert A. Vandermeulen and Hakan Bilen},
}
